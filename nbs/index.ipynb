{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc7af91",
   "metadata": {},
   "source": [
    "# remoteipy\n",
    "\n",
    "> remote python execution for SolveIt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eddde5",
   "metadata": {},
   "source": [
    "If you are not using [SolveIt](https://solve.it.com/) then this is probably not as relevant to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7202037",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b10d94",
   "metadata": {},
   "source": [
    "## Connecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002ad60",
   "metadata": {},
   "source": [
    "```python\n",
    "from remoteipy import connect, is_connected, disconnect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970e378",
   "metadata": {},
   "source": [
    "```python\n",
    "client = connect(\"ssh -p 16067 root@ssh3.vast.ai -L 8080:localhost:8080\", py=\"/venv/main/bin/python\")\n",
    "```\n",
    "```bash\n",
    "> Connected to IPython kernel at root@ssh3.vast.ai:16067\n",
    "Welcome to vast.ai. If authentication fails, try again after a few seconds, and double check your ssh key.\n",
    "Have fun!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9f519",
   "metadata": {},
   "source": [
    "```python\n",
    "is_connected(client)\n",
    "```\n",
    "```\n",
    "> True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7879baa",
   "metadata": {},
   "source": [
    "## Running code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08028e90",
   "metadata": {},
   "source": [
    "```python\n",
    "%%remote\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "```bash\n",
    "> 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ad67f",
   "metadata": {},
   "source": [
    "```python\n",
    "%%remote\n",
    "\n",
    "!nvidia-smi\n",
    "```\n",
    "```bash\n",
    "> Wed Dec 10 10:05:54 2025       \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:05:00.0 Off |                  Off |\n",
    "| N/A   29C    P0             76W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
    "|                                         |                        |             Disabled |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "                                                                                         \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|  No running processes found                                                             |\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67738169",
   "metadata": {},
   "source": [
    "## Asking SolveIt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90eec3c",
   "metadata": {},
   "source": [
    "What GPU am I running? Would you call me GPU-rich or GPU-poor ;)?\n",
    "\n",
    "\n",
    "> You're running an NVIDIA H100 80GB HBM3 â€” that's the flagship datacenter GPU from NVIDIA's Hopper generation!\n",
    "> \n",
    "> I'd definitely call you GPU-rich ðŸ¤‘ â€” that's one of the most powerful GPUs available for AI/ML workloads. The H100 80GB is what the big labs use for training large models. You've got:\n",
    "> \n",
    "> - 80GB of ultra-fast HBM3 memory\n",
    "> - Up to 700W of compute power at your fingertips\n",
    "> - CUDA 12.8 support\n",
    "> \n",
    "> You're sitting pretty! What are you planning to run on this beast?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbea441",
   "metadata": {},
   "source": [
    "## Running more code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe08bba",
   "metadata": {},
   "source": [
    "```python\r\n",
    "%%remote\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n",
    "A = torch.ones(4096, 4096, dtype=torch.float32, device=\"cuda\")\r\n",
    "A\r\n",
    "```\r\n",
    "```\r\n",
    "> tensor([[1., 1., 1.,  ..., 1., 1., 1.],\r\n",
    "        [1., 1., 1.,  ..., 1., 1., 1.],\r\n",
    "        [1., 1., 1.,  ..., 1., 1., 1.],\r\n",
    "        ...,\r\n",
    "        [1., 1., 1.,  ..., 1., 1., 1.],\r\n",
    "        [1., 1., 1.,  ..., 1., 1., 1.],\r\n",
    "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58cae8",
   "metadata": {},
   "source": [
    "What did I just do?\n",
    "\n",
    "> You just created a 4096Ã—4096 matrix filled with ones on your GPU (the H100)!\n",
    "> \n",
    "> Specifically:\n",
    "> - torch.ones() creates a tensor (PyTorch's version of an array) filled with 1s\n",
    "> - dtype=torch.float32 means each element is a 32-bit floating point number\n",
    "> - device=\"cuda\" puts it on your GPU memory instead of CPU RAM\n",
    "> This tensor is taking up about 64 MB of your GPU's 80GB memory (4096 Ã— 4096 Ã— 4 bytes per float32).\n",
    "> \n",
    "> \n",
    "> Are you planning to do some matrix operations or neural network work with this?You just created a 4096Ã—4096 matrix filled with ones on your GPU! Specifically, you:\n",
    "> \n",
    "> Created a PyTorch tensor with 32-bit floating point values\n",
    "> Allocated it directly on the CUDA device (your H100 GPU)\n",
    "> The tensor contains about 16.8 million elements (all set to 1.0)\n",
    "> This takes up about 64 MB of your GPU's 80 GB memory. Are you planning to do some matrix operations or neural network work with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eec0de",
   "metadata": {},
   "source": [
    "## Disconnecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d5e4e",
   "metadata": {},
   "source": [
    "```python\r\n",
    "disconnect(client)\r\n",
    "```\r\n",
    "```bash\r\n",
    "> Exit requrest sent.\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc48c8c",
   "metadata": {},
   "source": [
    "```python\r\n",
    "is_connected(client)\r\n",
    "```\r\n",
    "```bash\r\n",
    "> False\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefefd99",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9f1e7",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/achalpandeyy/remoteipy.git\n",
    "```\n",
    "\n",
    "```sh\n",
    "$ pip install remoteipy\n",
    "```\n",
    "\n",
    "\n",
    "[repo]: https://github.com/achalpandeyy/remoteipy\n",
    "[docs]: https://achalpandeyy.github.io/remoteipy/\n",
    "[pypi]: https://pypi.org/project/remoteipy/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87fe0c",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775d58e",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [pypi][pypi].\n",
    "\n",
    "[repo]: https://github.com/achalpandeyy/remoteipy\n",
    "[docs]: https://achalpandeyy.github.io/remoteipy/\n",
    "[pypi]: https://pypi.org/project/remoteipy/\n",
    "[conda]: https://anaconda.org/achalpandeyy/remoteipy"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
