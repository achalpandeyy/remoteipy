{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from remoteipy.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7af91",
   "metadata": {},
   "source": [
    "# remoteipy\n",
    "\n",
    "> remote python execution for SolveIt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eddde5",
   "metadata": {},
   "source": [
    "If you are not using SolveIt then this is probably not as relevant to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7202037",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b375ba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'remoteipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mremoteipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m connect, disconnect",
      "",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'remoteipy'"
     ]
    }
   ],
   "source": [
    "from remoteipy import connect, disconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Welcome to vast.ai. If authentication fails, try again after a few seconds, and double check your ssh key.\n",
      "Have fun!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bind [127.0.0.1]:50004: Address already in use\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to IPython kernel at root@ssh7.vast.ai:13027\n"
     ]
    }
   ],
   "source": [
    "# ssh -p 13027 root@ssh7.vast.ai -L 8080:localhost:8080\r\n",
    "client = connect(user=\"root\", host=\"ssh7.vast.ai\", port=13027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fdf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "%%remote\n",
    "\n",
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7b2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "%%remote\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6423c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  9 07:07:30 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:86:00.0 Off |                  Off |\r\n",
      "| N/A   31C    P0             73W /  700W |       0MiB /  81559MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "%%remote\r\n",
    "\r\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b2aa0",
   "metadata": {},
   "source": [
    "What GPU am I running? Is it a gaming one?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "You're running an **NVIDIA H100 80GB HBM3** â€” definitely not a gaming card! \n",
    "\n",
    "The H100 is NVIDIA's flagship data center GPU designed for AI training and high-performance computing. It's got 80GB of HBM3 (High Bandwidth Memory), which is much faster than the GDDR memory found in gaming GPUs. This is serious hardware for deep learning workloads.\n",
    "\n",
    "Are you planning to train some models on it, or just exploring what you can do with the remote kernel setup you've built?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea8ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exit request sent.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "disconnect(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefefd99",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9f1e7",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/achalpandeyy/remoteipy.git\n",
    "```\n",
    "\n",
    "or from [conda][conda]\n",
    "\n",
    "```sh\n",
    "$ conda install -c achalpandeyy remoteipy\n",
    "```\n",
    "\n",
    "or from [pypi][pypi]\n",
    "\n",
    "\n",
    "```sh\n",
    "$ pip install remoteipy\n",
    "```\n",
    "\n",
    "\n",
    "[repo]: https://github.com/achalpandeyy/remoteipy\n",
    "[docs]: https://achalpandeyy.github.io/remoteipy/\n",
    "[pypi]: https://pypi.org/project/remoteipy/\n",
    "[conda]: https://anaconda.org/achalpandeyy/remoteipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87fe0c",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775d58e",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [conda][conda] and [pypi][pypi] respectively.\n",
    "\n",
    "[repo]: https://github.com/achalpandeyy/remoteipy\n",
    "[docs]: https://achalpandeyy.github.io/remoteipy/\n",
    "[pypi]: https://pypi.org/project/remoteipy/\n",
    "[conda]: https://anaconda.org/achalpandeyy/remoteipy"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
